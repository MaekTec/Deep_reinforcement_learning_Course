{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN Atari Space Invaders Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaekTec/Deep_reinforcement_learning_Course/blob/solutions/Deep%20Q%20Learning/Space%20Invaders/DQN_Atari_Space_Invaders_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "G5JJE8i8hEeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import the libraries"
      ]
    },
    {
      "metadata": {
        "id": "cpYKA8AegYTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5d221b41-00f0-4531-cf46-50e4e75700a1"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf      # Deep Learning library\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Lambda, Multiply\n",
        "from keras import backend as K\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)\n",
        "\n",
        "import numpy as np           # Handle matrices\n",
        "import gym                 # Retro Environment\n",
        "\n",
        "\n",
        "from skimage import transform # Help us to preprocess the frames\n",
        "from skimage.color import rgb2gray # Help us to gray our frames\n",
        "\n",
        "import matplotlib.pyplot as plt # Display graphs\n",
        "\n",
        "from collections import deque# Ordered collection with ends\n",
        "\n",
        "import random\n",
        "\n",
        "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
        "warnings.filterwarnings('ignore') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CvvnMDXaim-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Create our environment"
      ]
    },
    {
      "metadata": {
        "id": "zx_tVa9EisLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8f989f84-b723-4653-fb59-e1323faec295"
      },
      "cell_type": "code",
      "source": [
        "# Create our environment\n",
        "env = gym.make('SpaceInvaders-v0')\n",
        "\n",
        "print(\"The size of our frame is: \", env.observation_space)\n",
        "print(\"The action size is : \", env.action_space.n)\n",
        "\n",
        "# Here we create an hot encoded version of our actions\n",
        "# possible_actions = [0, 1, 2, 3, ...]\n",
        "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of our frame is:  Box(210, 160, 3)\n",
            "The action size is :  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k_J-CIaFixy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define the preprocessing functions"
      ]
    },
    {
      "metadata": {
        "id": "oU0bGcM1i3o1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    preprocess_frame:\n",
        "    Take a frame.\n",
        "    Grayscale it\n",
        "    Resize it.\n",
        "        __________________\n",
        "        |                 |\n",
        "        |                 |\n",
        "        |                 |\n",
        "        |                 |\n",
        "        |_________________|\n",
        "        \n",
        "        to\n",
        "        _____________\n",
        "        |            |\n",
        "        |            |\n",
        "        |            |\n",
        "        |____________|\n",
        "    Normalize it.\n",
        "    \n",
        "    return preprocessed_frame\n",
        "    \n",
        "    \"\"\"\n",
        "def preprocess_frame(frame):\n",
        "    # Greyscale frame \n",
        "    gray = rgb2gray(frame)\n",
        "    \n",
        "    # Crop the screen (remove the part below the player)\n",
        "    # [Up: Down, Left: right]\n",
        "    cropped_frame = gray[8:-12,4:-12]\n",
        "    \n",
        "    # Normalize Pixel Values\n",
        "    normalized_frame = cropped_frame/255.0\n",
        "    \n",
        "    # Resize\n",
        "    # Thanks to Miko≈Çaj Walkowiak\n",
        "    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n",
        "    \n",
        "    return preprocessed_frame # 110x84x1 frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXscL9fyi8Em",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stack_size = 4 # We stack 4 frames\n",
        "\n",
        "# Initialize deque with zero-images one array for each image\n",
        "stacked_frames  =  deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "\n",
        "def stack_frames(stacked_frames, state, is_new_episode):\n",
        "    # Preprocess frame\n",
        "    frame = preprocess_frame(state)\n",
        "    \n",
        "    if is_new_episode:\n",
        "        # Clear our stacked_frames\n",
        "        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "        \n",
        "        # Because we're in a new episode, copy the same frame 4x\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        \n",
        "        # Stack the frames\n",
        "        stacked_state = np.stack(stacked_frames, axis=2)\n",
        "        \n",
        "    else:\n",
        "        # Append frame to deque, automatically removes the oldest frame\n",
        "        stacked_frames.append(frame)\n",
        "\n",
        "        # Build the stacked state (first dimension specifies different frames)\n",
        "        stacked_state = np.stack(stacked_frames, axis=2) \n",
        "    \n",
        "    return stacked_state, stacked_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "exjFotpCi_l3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Set up our hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "Wn_j-g9fjDW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### MODEL HYPERPARAMETERS\n",
        "state_size = [110, 84, 4]      # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n",
        "action_size = env.action_space.n # 8 possible actions\n",
        "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
        "\n",
        "### TRAINING HYPERPARAMETERS\n",
        "total_episodes = 100            # Total episodes for training\n",
        "max_steps = 50000              # Max possible steps in an episode\n",
        "batch_size = 64                # Batch size\n",
        "\n",
        "# Exploration parameters for epsilon greedy strategy\n",
        "explore_start = 1.0            # exploration probability at start\n",
        "explore_stop = 0.01            # minimum exploration probability \n",
        "decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
        "\n",
        "# Q learning hyperparameters\n",
        "gamma = 0.9                    # Discounting rate\n",
        "\n",
        "### MEMORY HYPERPARAMETERS\n",
        "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
        "memory_size = 20000          # Number of experiences the Memory can keep\n",
        "\n",
        "### PREPROCESSING HYPERPARAMETERS\n",
        "stack_size = 4                 # Number of frames stacked\n",
        "\n",
        "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
        "training = True\n",
        "\n",
        "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
        "episode_render = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_BSCHcUjIR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5: Create our Deep Q-learning Neural Network model"
      ]
    },
    {
      "metadata": {
        "id": "JsSX32gsjOqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQNetwork:\n",
        "  def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        self.inputs_ = Input(shape=(*self.state_size,), dtype='float32')\n",
        "        self.actions_ = Input(shape=(self.action_size,), dtype='float32')\n",
        "        #self.target_Q = Input(shape=(1,), dtype='float32')\n",
        "        \n",
        "        conv1 = Conv2D(32, [8, 8], strides=[4, 4], padding='valid', activation='elu')(self.inputs_)\n",
        "        conv2 = Conv2D(64, [4, 4], strides=[2, 2], padding='valid', activation='elu')(conv1)\n",
        "        conv3 = Conv2D(64, [3, 3], strides=[2, 2], padding='valid', activation='elu')(conv2)\n",
        "        flatten = Flatten()(conv3)\n",
        "        fc = Dense(512, activation='elu')(flatten)\n",
        "        output = Dense(self.action_size, activation='elu')(fc)\n",
        "        \n",
        "        ReduceSum = Lambda(lambda z: K.sum(z, axis=1))\n",
        "        Q = ReduceSum(Multiply()([output, self.actions_]))\n",
        "        \n",
        "        adam = optimizers.Adam(lr=self.learning_rate)\n",
        "        model = Model(inputs=[self.inputs_, self.actions_], outputs=Q)\n",
        "        model.compile(optimizer=adam, loss='mean_squared_error', metrics=['accuracy'])\n",
        "        \n",
        "        print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XoRmiTp_svqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "37ab9e88-dfe6-4acf-a0e1-76035a8700b4"
      },
      "cell_type": "code",
      "source": [
        "DQNetwork = DQNetwork(state_size, action_size, learning_rate)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 110, 84, 4)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 26, 20, 32)   8224        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 12, 9, 64)    32832       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 5, 4, 64)     36928       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          655872      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            3078        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 6)            0           dense_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None,)              0           multiply[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 736,934\n",
            "Trainable params: 736,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}